# UPDATE ALL MODEL NAMES - Copy to Replit

## CRITICAL: Update all AI model names in the codebase

Search and replace ALL model names in the project. Here are the CORRECT, VERIFIED model names:

### CORRECT MODEL NAMES (Tested & Working December 2025):

```
OpenAI:     gpt-5.2
Anthropic:  claude-opus-4-5-20251101
Google:     gemini-3-flash-preview
DeepSeek:   deepseek-chat
Perplexity: sonar
xAI/Grok:   grok-4
```

### IMPORTANT: OpenAI Parameter Change

For OpenAI GPT-5.2, use `max_completion_tokens` instead of `max_tokens`:

```typescript
// WRONG ❌
const result = await openai.chat.completions.create({
  model: 'gpt-5.2',
  max_tokens: 1000,  // ❌ NOT SUPPORTED
  ...
});

// CORRECT ✅
const result = await openai.chat.completions.create({
  model: 'gpt-5.2',
  max_completion_tokens: 1000,  // ✅ USE THIS
  ...
});
```

### Find and Replace These OLD Model Names:

```
OLD → NEW
gpt-4o → gpt-5.2
gpt-4 → gpt-5.2
gpt-4-turbo → gpt-5.2
claude-sonnet-4-20250514 → claude-opus-4-5-20251101
claude-3-sonnet → claude-opus-4-5-20251101
claude-3-opus → claude-opus-4-5-20251101
gemini-1.5-flash → gemini-3-flash-preview
gemini-2.0-flash → gemini-3-flash-preview
gemini-pro → gemini-3-flash-preview
grok-2 → grok-4
grok-beta → grok-4
sonar-pro → sonar
```

### Update These Files (search for model names):

1. `server/routes/llmCouncil.ts` or similar - The 6 AI Council
2. `server/routes/onboarding.ts` - Onboarding chat
3. Any other file that calls AI APIs

### Example Updated Code for LLM Council:

```typescript
// AI Model Configuration - CORRECT December 2025
const AI_MODELS = {
  openai: {
    model: 'gpt-5.2',
    // NOTE: Use max_completion_tokens, NOT max_tokens
  },
  anthropic: {
    model: 'claude-opus-4-5-20251101',  // JUDGE - Best for judgment
  },
  gemini: {
    model: 'gemini-3-flash-preview',
  },
  deepseek: {
    model: 'deepseek-chat',
  },
  perplexity: {
    model: 'sonar',  // Real-time web search
  },
  grok: {
    model: 'grok-4',  // X/Twitter data access
  }
};
```

### Example OpenAI Call (with correct parameter):

```typescript
async function searchWithGPT() {
  const result = await openai.chat.completions.create({
    model: 'gpt-5.2',
    max_completion_tokens: 2000,  // ✅ NOT max_tokens
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: query }
    ]
  });
  return result.choices[0].message.content;
}
```

### Example Anthropic Call:

```typescript
async function searchWithClaude() {
  const result = await anthropic.messages.create({
    model: 'claude-opus-4-5-20251101',
    max_tokens: 2000,
    messages: [
      { role: 'user', content: query }
    ]
  });
  return result.content[0].text;
}
```

### Example Google Gemini Call:

```typescript
async function searchWithGemini() {
  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent?key=${process.env.GOOGLE_AI_API_KEY}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents: [{ parts: [{ text: query }] }]
      })
    }
  );
  const data = await response.json();
  return data.candidates[0].content.parts[0].text;
}
```

### Example xAI/Grok Call:

```typescript
async function searchWithGrok() {
  const result = await grok.chat.completions.create({
    model: 'grok-4',
    max_tokens: 2000,
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: query }
    ]
  });
  return result.choices[0].message.content;
}
```

### Example Perplexity Call:

```typescript
async function searchWithPerplexity() {
  const result = await perplexity.chat.completions.create({
    model: 'sonar',
    max_tokens: 2000,
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: query }
    ]
  });
  return result.choices[0].message.content;
}
```

### Example DeepSeek Call:

```typescript
async function searchWithDeepSeek() {
  const result = await deepseek.chat.completions.create({
    model: 'deepseek-chat',
    max_tokens: 2000,
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: query }
    ]
  });
  return result.choices[0].message.content;
}
```

---

## SUMMARY - Just do these 2 things:

1. **Replace all model names** with the correct ones listed above
2. **For OpenAI only**: Change `max_tokens` → `max_completion_tokens`

After updating, restart the server and test the onboarding chat!